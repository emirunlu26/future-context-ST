{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMVnuorD4lfV/M+0WTBQkpo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emirunlu26/future-context-ST/blob/main/code/asr_mt_test_on_whisper_nllb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "YCrDCfa5vNFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "threshold = 750 # number of segment informations to read"
      ],
      "metadata": {
        "id": "ZexBr2qEdSC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "duration_class_by_upper_bound = {\"1\":5,\"2\":10,\"3\":15,\"4\":20}\n",
        "duration_class_by_size = {\"1\":0,\"2\":0,\"3\":0,\"4\":0}\n",
        "duration_class_by_percentage = {\"1\":0,\"2\":0,\"3\":0,\"4\":0}\n",
        "\n",
        "highest_duration = 0\n",
        "\n",
        "for index in range(threshold):\n",
        "  audio_name = \"audio_\" + str(index) + \".wav\"\n",
        "  audio_path = \"/content/drive/MyDrive/ColabNotebooks/audio_segments_test_set/\" + audio_name\n",
        "  audio, sample_rate = librosa.load(audio_path,sr=None)\n",
        "  duration = len(audio) / sample_rate\n",
        "\n",
        "  if duration > highest_duration:\n",
        "    highest_duration = duration\n",
        "\n",
        "  for duration_class in duration_class_by_upper_bound:\n",
        "    if duration < duration_class_by_upper_bound[duration_class]:\n",
        "      duration_class_by_size[duration_class] += 1\n",
        "      break\n",
        "print(\"\\n\\n\")\n",
        "print(\"Highest duration is:\", highest_duration)\n",
        "print(duration_class_by_size)\n",
        "\n",
        "for duration_class in duration_class_by_percentage:\n",
        "  duration_class_by_percentage[duration_class] = round(duration_class_by_size[duration_class] / threshold,3) * 100\n",
        "\n",
        "print(duration_class_by_percentage)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kT0RDMtQJRLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "start_index = 500\n",
        "threshold = 750\n",
        "\n",
        "# STORE THE SEGMENT INFORMATIONS IN segment_infos LIST\n",
        "segment_infos = list()\n",
        "\n",
        "with open(\"/content/drive/MyDrive/ColabNotebooks/segments.lst\",\"r\") as segment_file:\n",
        "  segment_lines = segment_file.readlines()\n",
        "\n",
        "  print(f\"Total number of segment infos is {len(segment_lines)}\")\n",
        "  segment_lines = segment_lines[start_index:]\n",
        "  for line in segment_lines:\n",
        "    segment_info = line[0:len(line)-1].split()\n",
        "    segment_infos.append(segment_info)\n",
        "\n",
        "    if len(segment_infos) == threshold:\n",
        "      break\n",
        "\n",
        "  segment_infos = np.array(segment_infos)\n",
        "\n",
        "  print(f\"Length of segment_infos is {len(segment_infos)}\")\n",
        "\n",
        "  '''\n",
        "  last_unique_audio = None\n",
        "  unique_audioset = list()\n",
        "  for segment_info in segment_infos:\n",
        "    if last_unique_audio == segment_info[0]:\n",
        "      continue\n",
        "    unique_audioset.append(segment_info[0])\n",
        "    last_unique_audio = segment_info[0]\n",
        "    print(segment_info[0])\n",
        "  '''\n",
        "\n",
        "# GET THE AUDIO DATA FOR THE AUDIO SEGMENTS\n",
        "  audio_segments = list()\n",
        "\n",
        "  for index, segment in enumerate(segment_infos):\n",
        "    audio_path = \"/content/drive/MyDrive/ColabNotebooks/audios_test_set/\" + segment[0] + \".m4a\"\n",
        "    audio_data, sample_rate = librosa.load(audio_path)\n",
        "    start_sec = float(segment[1])\n",
        "    end_sec = float(segment[2])\n",
        "    start_sample = int(start_sec * sample_rate)\n",
        "    end_sample = int(end_sec * sample_rate)\n",
        "    audio_segment = audio_data[start_sample:end_sample]\n",
        "\n",
        "    # Define output path\n",
        "    output_path = f\"/content/drive/MyDrive/ColabNotebooks/audio_segments_test_set/audio_{index}.wav\"\n",
        "\n",
        "    # Save the segment\n",
        "    sf.write(output_path, audio_segment, sample_rate)\n",
        "    print(f\"Audio number {index+1} written ...\")\n",
        "\n",
        "    audio_segments.append(audio_segment)"
      ],
      "metadata": {
        "id": "FloNCRI2pCSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**en.20101216.19.4-271.m4a**"
      ],
      "metadata": {
        "id": "LuUGDE1ZtMdt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GET THE TRANSCRIPTIONS BELONGING TO THE FIRST 500 AUDIO SEGMENTS"
      ],
      "metadata": {
        "id": "TIWMycI7HbrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/ColabNotebooks/segments.en\",\"r\") as transcr_file:\n",
        "  ref_transcriptions = list()\n",
        "  for transcription in transcr_file:\n",
        "    transcription = transcription[:len(transcription)-1]\n",
        "    ref_transcriptions.append(transcription)\n",
        "    if len(ref_transcriptions) == threshold:\n",
        "      break"
      ],
      "metadata": {
        "id": "ILc7-6GyAiBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GET THE GERMAN TRANSLATIONS OF THE FIRST 500 TRANSCRIPTIONS"
      ],
      "metadata": {
        "id": "Sff_QKDdHo0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/ColabNotebooks/segments.de\",\"r\") as translate_file:\n",
        "  ref_translations = list()\n",
        "  for translation in translate_file:\n",
        "    translation = translation[:len(translation)-1]\n",
        "    ref_translations.append(translation)\n",
        "    if len(ref_translations) == threshold:\n",
        "      break\n",
        "  ref_translations = [ref_translations]"
      ],
      "metadata": {
        "id": "9sK1bJH4HuGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GET MODEL BY USING PIPELINE**"
      ],
      "metadata": {
        "id": "XSnDEvyaDQH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install -U openai-whisper\n",
        "!pip install --upgrade soundfile"
      ],
      "metadata": {
        "id": "qCjhBhUZXXSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYH79KRoi-KS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "whisper = pipeline(\"automatic-speech-recognition\", \"openai/whisper-large-v3\", torch_dtype=torch.float16, device=\"cuda:0\")\n",
        "\n",
        "whisper_transcriptions = map(whisper, audio_segments)\n",
        "whisper_transcriptions = list(map(lambda x: x[\"text\"], whisper_transcriptions))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GET MODEL BY CALLING whisper.load_model()**"
      ],
      "metadata": {
        "id": "xoupoewBDapp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "model = whisper.load_model(\"turbo\").to(\"cuda\")\n",
        "whisper_transcriptions = list()\n",
        "\n",
        "for index in range(threshold):\n",
        "  audio_path = \"/content/drive/MyDrive/ColabNotebooks/audio_segments_new/audio_\" + str(index) + \".wav\"\n",
        "  audio, sample_rate = librosa.load(audio_path,sr=None)\n",
        "  audio = whisper.pad_or_trim(np.array(audio).astype(\"float32\"))\n",
        "  mel = whisper.log_mel_spectrogram(audio,n_mels=model.dims.n_mels).to(model.device)\n",
        "\n",
        "  options = whisper.DecodingOptions(language=\"en\")\n",
        "  result = whisper.decode(model, mel, options)\n",
        "  whisper_transcriptions.append(result.text)"
      ],
      "metadata": {
        "id": "VgVUgVtMrJFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOAD THE PREDICTIONS GENERATED BY WHISPER IN SIMULEVAL**"
      ],
      "metadata": {
        "id": "XNEpHPyWbbj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/ColabNotebooks/SimulEval/Whisper-Wait-k/predicted_transcriptions.txt\",\"r\") as whisper_simuleval_predictions:\n",
        "  simuleval_transcriptions = whisper_simuleval_predictions.readlines()\n",
        "  simuleval_transcriptions = list(map(lambda x: x[:len(x)-1], simuleval_transcriptions))"
      ],
      "metadata": {
        "id": "gR16GdATbbGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EVALUATE SIMULEVAL WHISPER RESULTS**"
      ],
      "metadata": {
        "id": "T47PSiyqcseP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from jiwer import wer, mer, wil, wip, cer\n",
        "\n",
        "# CALCULATE WORD ERROR RATE\n",
        "wer_scores = list()\n",
        "\n",
        "for ref, pred in zip(ref_transcriptions, simuleval_transcriptions):\n",
        "  wer_scores.append(wer(ref, pred))\n",
        "\n",
        "wer_scores = np.array(wer_scores)\n",
        "print(wer_scores.mean())\n"
      ],
      "metadata": {
        "id": "-y93EW6jcyDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUATE WHISPER BY USING **jiwer**"
      ],
      "metadata": {
        "id": "OgZ1WFYLdWIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer"
      ],
      "metadata": {
        "id": "JMN3dTzpd2-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from jiwer import wer, mer, wil, wip, cer\n",
        "\n",
        "# CALCULATE WORD ERROR RATE\n",
        "wer_scores = list()\n",
        "\n",
        "for ref, pred in zip(ref_transcriptions, whisper_transcriptions):\n",
        "  wer_scores.append(wer(ref, pred))\n",
        "\n",
        "wer_scores = np.array(wer_scores)\n",
        "\n",
        "# CALCULATE MATCH ERROR RATE\n",
        "mer_scores = list()\n",
        "\n",
        "for ref, pred in zip(ref_transcriptions, whisper_transcriptions):\n",
        "  mer_scores.append(mer(ref, pred))\n",
        "\n",
        "mer_scores = np.array(mer_scores)\n",
        "\n",
        "# CALCULATE WORD INFORMATION LOST\n",
        "wil_scores = list()\n",
        "\n",
        "for ref, pred in zip(ref_transcriptions, whisper_transcriptions):\n",
        "  wil_scores.append(wil(ref, pred))\n",
        "\n",
        "wil_scores = np.array(wil_scores)\n",
        "\n",
        "# CALCULATE WORD INFORMATION PRESERVED\n",
        "\n",
        "wip_scores = np.ones(len(wil_scores)) - wil_scores\n",
        "\n",
        "# CALCULATE CHARACTER ERROR RATE\n",
        "cer_scores = list()\n",
        "\n",
        "for ref, pred in zip(ref_transcriptions, whisper_transcriptions):\n",
        "  cer_scores.append(cer(ref, pred))\n",
        "\n",
        "cer_scores = np.array(cer_scores)"
      ],
      "metadata": {
        "id": "sEnx2nXxddOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(wer_scores.mean())\n",
        "print(wil_scores.mean())\n",
        "print(wip_scores.mean())"
      ],
      "metadata": {
        "id": "Uki_XHE3V8Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STORE THE MEAN OF EACH EVALUATION METRIC IN A DATAFRAME"
      ],
      "metadata": {
        "id": "73HPAuicgYbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "whisper_eval_results = {\"WER\": wer_scores.mean(), \"MER\": mer_scores.mean(), \"WIL\": wil_scores.mean(), \"WIP\": wip_scores.mean(), \"CER\": cer_scores.mean()}\n",
        "#whisper_eval_results = {\"WER\": wer_scores.mean()}\n",
        "\n",
        "asr_eval_results_df = pd.DataFrame(whisper_eval_results, index=[\"Whisper Turbo\"])\n",
        "asr_eval_results_df.index.name = \"ASR Model\"\n",
        "asr_eval_results_df.title = \"ASR Evaluation Results on First 30 Audio Segments\"\n",
        "\n",
        "asr_eval_results_df.to_csv(\"/content/drive/MyDrive/ColabNotebooks/asr_eval_results.csv\")"
      ],
      "metadata": {
        "id": "xXEu9Do2gXwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GET THE TRANSLATION PREDICTIONS GENERATED BY **NLLB** (INPUT: TRANSCRIPTIONS PROVIDED BY EUROPARL)"
      ],
      "metadata": {
        "id": "A3GVaMzFkQe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "model_name = \"facebook/nllb-200-distilled-600M\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name,src_lang=\"eng_Latn\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(\"cuda\")\n",
        "\n",
        "# DEFINE FUNCTION THAT APPLIES TRANSLATION\n",
        "\n",
        "def from_eng_to_ger(eng_text):\n",
        "  input_tokens = tokenizer(eng_text, return_tensors=\"pt\").to(\"cuda\")\n",
        "  output_tokens = model.generate(\n",
        "    **input_tokens, forced_bos_token_id=tokenizer.convert_tokens_to_ids(\"deu_Latn\"), max_length=50)\n",
        "  ger_text = tokenizer.batch_decode(output_tokens, skip_special_tokens=True)[0]\n",
        "  return ger_text\n",
        "\n",
        "# TRANSLATE SEGMENTED TEXTUAL DATA BY USING NLLB MODEL\n",
        "\n",
        "source_texts = ref_transcriptions\n",
        "nllb_translations = list(map(from_eng_to_ger, source_texts))"
      ],
      "metadata": {
        "id": "TiUIJ5KwlMZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "model_name = \"facebook/nllb-200-distilled-600M\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name,src_lang=\"eng_Latn\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(\"cuda\")\n",
        "\n",
        "text = ref_transcriptions[22]\n",
        "source_text = text\n",
        "source_text_encoding = tokenizer(source_text,return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "output_tokens = model.generate(\n",
        "            **source_text_encoding,\n",
        "            decoder_input_ids = None,\n",
        "            forced_bos_token_id = tokenizer.convert_tokens_to_ids(\"deu_Latn\"),\n",
        "            max_new_tokens = 50,\n",
        "        )\n",
        "\n",
        "output_text = tokenizer.batch_decode(output_tokens, skip_special_tokens=True)[0]\n",
        "\n",
        "print(\"Input id:\", source_text_encoding[\"input_ids\"])\n",
        "print()\n",
        "print(\"Output text:\", output_text)\n",
        "print()\n",
        "print(\"Output tokens:\", output_tokens)"
      ],
      "metadata": {
        "id": "Dkk8BssOBBFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GET THE TRANSLATION PREDICTIONS GENERATED BY MARIAN NMT (INPUT: TRANSCRIPTIONS PROVIDED BY EUROPARL)**"
      ],
      "metadata": {
        "id": "qeEP_hTs_EMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "model_name = \"Helsinki-NLP/opus-mt-en-de\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name).to(\"cuda\")\n",
        "\n",
        "def from_eng_to_ger_marian(eng_text):\n",
        "  input_tokens = tokenizer(eng_text, return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
        "  output_tokens = model.generate(**input_tokens)\n",
        "  ger_text = tokenizer.batch_decode(output_tokens, skip_special_tokens=True)[0]\n",
        "  return ger_text\n",
        "\n",
        "source_texts = ref_transcriptions\n",
        "marian_translations = list(map(from_eng_to_ger_marian, source_texts))"
      ],
      "metadata": {
        "id": "34T72_Sm_Js9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EVALUATION OF SIMULEVAL TRANSLATIONS**"
      ],
      "metadata": {
        "id": "YhQrqhbM-X1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/ColabNotebooks/SimulEval/NLLB-Wait-k/nllb_output.txt\"\n",
        "#path = \"/content/drive/MyDrive/ColabNotebooks/results/nllb_online_ref_transcriptions (simuleval)/nllb_k_3_output_2/output.txt\"\n",
        "with open(path,\"r\") as simuleval_file:\n",
        "  simuleval_translations = simuleval_file.readlines()\n",
        "  simuleval_translations = list(map(lambda x: x[:len(x)-1], simuleval_translations))"
      ],
      "metadata": {
        "id": "jSJVMgux8FvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/ColabNotebooks/SimulEval/NLLB-Wait-k/nllb_k_5_output_2.txt\",\"r\") as simuleval_file:\n",
        "  simuleval_translations_2 = simuleval_file.readlines()\n",
        "  simuleval_translations_2 = list(map(lambda x: x[:len(x)-1], simuleval_translations_2))"
      ],
      "metadata": {
        "id": "Yx3C9_7LnxiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from jiwer import wer, mer, wil, wip, cer\n",
        "\n",
        "# CALCULATE WORD ERROR RATE\n",
        "wer_scores = list()\n",
        "upper_limit = 0.9\n",
        "count = 0\n",
        "\n",
        "for i in range(500):\n",
        "  wer_score = wer(simuleval_translations[i], simuleval_translations_2[i])\n",
        "  if wer_score > upper_limit:\n",
        "    count +=1\n",
        "    print(\"Index:\", i)\n",
        "    print(\"WER:\", wer_score)\n",
        "    print(\"Translation 1:\", simuleval_translations[i])\n",
        "    print(\"Translation 2:\", simuleval_translations_2[i] + \"\\n\")\n",
        "print(\"\\nCount:\", count)"
      ],
      "metadata": {
        "id": "IgJketpFnptb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu\n",
        "\n",
        "nllb_bleu = sacrebleu.corpus_bleu(simuleval_translations, ref_translations)\n",
        "\n",
        "print(nllb_bleu.score)\n",
        "print(nllb_bleu)"
      ],
      "metadata": {
        "id": "xE_3Ugha9jV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EVALUATION OF SIMULEVAL TRANSLATIONS - THE END**"
      ],
      "metadata": {
        "id": "Ue1qAV2W-hck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUATE NLLB BY USING **sacreBLEU** (INPUT: TRANSCRIPTIONS PROVIDED BY EUROPARL)"
      ],
      "metadata": {
        "id": "F-vGN-D5juTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu"
      ],
      "metadata": {
        "id": "9OVh-QgYoTgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu\n",
        "\n",
        "nllb_bleu = sacrebleu.corpus_bleu(nllb_translations, ref_translations)\n",
        "print(nllb_bleu)"
      ],
      "metadata": {
        "id": "P7L8zQy-Z8Lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu\n",
        "import pandas as pd\n",
        "\n",
        "nllb_bleu = sacrebleu.corpus_bleu(nllb_translations, ref_translations)\n",
        "\n",
        "nllb_bleu_df = pd.DataFrame({\"sacreBLEU(on 500 segments)\": nllb_bleu.score}, index=[\"nllb-200-distilled-600M\"])\n",
        "nllb_bleu_df.index.name = \"MT Model\"\n",
        "\n",
        "nllb_bleu_df.to_csv(\"/content/drive/MyDrive/ColabNotebooks/nllb_bleu.csv\")\n"
      ],
      "metadata": {
        "id": "AofPsfVOjqm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/ColabNotebooks/nllb_offline_output.txt\", \"w\", encoding=\"utf-8\") as target:\n",
        "  for translation in nllb_translations:\n",
        "    target.write(translation + \"\\n\")"
      ],
      "metadata": {
        "id": "omofW4-cfsut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GET THE TRANSLATION PREDICTIONS GENERATED BY NLLB (INPUT: TRANSCRIPTIONS GENERATED BY WHISPER)**"
      ],
      "metadata": {
        "id": "EMPWG9kF3Dvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nllb_translations = list(map(from_eng_to_ger, whisper_transcriptions))"
      ],
      "metadata": {
        "id": "pTxaaZyI3aiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/ColabNotebooks/results/nllb_offline_hypo_transcriptions/output.txt\", \"w\", encoding=\"utf-8\") as target:\n",
        "  for translation in nllb_translations:\n",
        "    target.write(translation + \"\\n\")"
      ],
      "metadata": {
        "id": "rweyWSDFjK89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EVALUATE NLLB BY USING sacreBLEU (INPUT: TRANSCRIPTIONS GENERATED BY WHISPER)**"
      ],
      "metadata": {
        "id": "YDadNDxF4f7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu\n",
        "import pandas as pd\n",
        "\n",
        "nllb_bleu = sacrebleu.corpus_bleu(nllb_translations, ref_translations)\n",
        "\n",
        "nllb_bleu_df = pd.DataFrame({\"sacreBLEU(on 500 segments)\": nllb_bleu.score}, index=[\"nllb-200-distilled-600M\"])\n",
        "nllb_bleu_df.index.name = \"MT Model\"\n",
        "\n",
        "nllb_bleu_df.to_csv(\"/content/drive/MyDrive/ColabNotebooks/evaluations/nllb_offline_hypo_transcriptions/nllb_bleu_hypothesis_input.csv\")\n"
      ],
      "metadata": {
        "id": "wxVA1CHm43xR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**COMPARE OUTPUTS OF DIFFERENT CASCADED SETUPS (MODELS NOT INTERCONNECTED)**"
      ],
      "metadata": {
        "id": "k1UNoCVa8kbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/ColabNotebooks/SimulEval/NLLB-Wait-k/translation_simuleval_2.txt\",\"r\") as simuleval_file:\n",
        "  simuleval_translations = simuleval_file.readlines()\n",
        "  simuleval_translations = list(map(lambda x: x[:len(x)-1], simuleval_translations))"
      ],
      "metadata": {
        "id": "SMjqdopi8j0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/ColabNotebooks/SimulEval/NLLB-Wait-k/translation_simuleval_4.txt\",\"r\") as simuleval_file:\n",
        "  simuleval_translations_2 = simuleval_file.readlines()\n",
        "  simuleval_translations_2 = list(map(lambda x: x[:len(x)-1], simuleval_translations_2))"
      ],
      "metadata": {
        "id": "njqbKrsA8zcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from jiwer import wer, mer, wil, wip, cer\n",
        "\n",
        "# CALCULATE WORD ERROR RATE\n",
        "wer_scores = list()\n",
        "\n",
        "for ref, pred in zip(simuleval_translations, simuleval_translations_2):\n",
        "  wer_scores.append(wer(ref, pred))\n",
        "\n",
        "wer_scores = np.array(wer_scores)\n",
        "print(wer_scores.mean())"
      ],
      "metadata": {
        "id": "m4JVtxfV861R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu\n",
        "\n",
        "nllb_bleu = sacrebleu.corpus_bleu(simuleval_translations, ref_translations)\n",
        "\n",
        "print(nllb_bleu.score)"
      ],
      "metadata": {
        "id": "knRSQ9RJ9ra6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu\n",
        "\n",
        "nllb_bleu = sacrebleu.corpus_bleu(simuleval_translations_2, ref_translations)\n",
        "\n",
        "print(nllb_bleu.score)"
      ],
      "metadata": {
        "id": "Zdm5_iMq99Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CALCULATE BLEU SCORE OF OUTPUTS FROM REAL CASCADED SETUPS (MODELS INTERCONNECTED)**"
      ],
      "metadata": {
        "id": "BIQ6kuUbQXQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/ColabNotebooks/SimulEval/Cascaded-Wait-k/cascaded_setup_2_results.txt\",\"r\") as cascaded_output_file:\n",
        "  cascaded_translations = cascaded_output_file.readlines()\n",
        "  cascaded_translations = list(map(lambda x: x[:len(x)-1], cascaded_translations))"
      ],
      "metadata": {
        "id": "MOU8hwdEQWnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu\n",
        "\n",
        "nllb_bleu = sacrebleu.corpus_bleu(cascaded_translations, ref_translations)\n",
        "\n",
        "print(nllb_bleu.score)"
      ],
      "metadata": {
        "id": "rvkErdrZRN7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**COMPARE OUTPUTS FROM REAL CASCADED SETUPS WITH EACH OTHER (MODELS INTERCONNECTED)**"
      ],
      "metadata": {
        "id": "DXo7G-VaWb6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/ColabNotebooks/SimulEval/Cascaded-Wait-k/cascaded_setup_3_results.txt\",\"r\") as cascaded_output_file:\n",
        "  cascaded_translations_1 = cascaded_output_file.readlines()\n",
        "  cascaded_translations_1 = list(map(lambda x: x[:len(x)-1], cascaded_translations_1))"
      ],
      "metadata": {
        "id": "QAq0_IEgWXCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/ColabNotebooks/SimulEval/Cascaded-Wait-k/cascaded_setup_4_results.txt\",\"r\") as cascaded_output_file_2:\n",
        "  cascaded_translations_2 = cascaded_output_file_2.readlines()\n",
        "  cascaded_translations_2 = list(map(lambda x: x[:len(x)-1], cascaded_translations_2))"
      ],
      "metadata": {
        "id": "MhN8k_yRWjo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from jiwer import wer, mer, wil, wip, cer\n",
        "\n",
        "# CALCULATE WORD ERROR RATE\n",
        "wer_scores = list()\n",
        "\n",
        "for ref, pred in zip(cascaded_translations_1, cascaded_translations_2):\n",
        "  wer_scores.append(wer(ref, pred))\n",
        "\n",
        "wer_scores = np.array(wer_scores)\n",
        "print(wer_scores.mean())"
      ],
      "metadata": {
        "id": "C_fSdPGcWs5d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}